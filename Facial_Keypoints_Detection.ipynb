{
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "Facial Keypoints Detection",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 3486,
          "databundleVersionId": 31310,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30673,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MissoumYoucef/Kaggle_Competition/blob/main/Facial_Keypoints_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'facial-keypoints-detection:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-competitions-data%2Fkaggle-v2%2F3486%2F31310%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240404%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240404T000520Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D5906d777f8d549ab60e105307d420140ba8a9b9d4713ad3fe790d5850f15a7a392e991d05b79a0feb1e3aef9233900a874d1abf713c8e29bb8b23fcf9ab11e172d1614714e38614a34bcd33bb10a99c33e9c803c72fdd7bfe871fa70a2a622566b188bea9236a165b68a3b94222a93090a78787582e84e1e898b35389f3b040fb406c0addbbdac8a81e0fe00a875af367077d56b5aef522e57d0563444edbfa072c7b6a887bd63a73411955b6eaea959c3f33dca2ccc5107fb45180797c0278e339783dde8d7a73c82fa1c5bac21a3c1cd41b828b23356b128d156f26299844373222487929942076774d1a7a31ce829cbf2063b2129dd97ff04f55199f7ac43'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "N5fqLixxbUtx"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Conv2D,Dropout,Dense,Flatten\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Activation, Convolution2D, MaxPooling2D, BatchNormalization, Flatten, Dense, Dropout, Conv2D,MaxPool2D, ZeroPadding2D\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "Z7lZb98F6Tp9",
        "execution": {
          "iopub.status.busy": "2024-04-03T23:27:58.182787Z",
          "iopub.execute_input": "2024-04-03T23:27:58.18324Z",
          "iopub.status.idle": "2024-04-03T23:28:16.489147Z",
          "shell.execute_reply.started": "2024-04-03T23:27:58.183205Z",
          "shell.execute_reply": "2024-04-03T23:28:16.488222Z"
        },
        "trusted": true,
        "outputId": "10ba73b0-1348-4ced-b070-666c49ca2f9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "2024-04-03 23:28:00.857140: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-03 23:28:00.857291: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-03 23:28:01.055037: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv('/kaggle/input/facial-keypoints-detection/training.zip')\n",
        "test_data = pd.read_csv('/kaggle/input/facial-keypoints-detection/test.zip')"
      ],
      "metadata": {
        "id": "tzQ-XE7SJRHs",
        "execution": {
          "iopub.status.busy": "2024-04-03T23:28:24.739326Z",
          "iopub.execute_input": "2024-04-03T23:28:24.740784Z",
          "iopub.status.idle": "2024-04-03T23:28:31.059428Z",
          "shell.execute_reply.started": "2024-04-03T23:28:24.740741Z",
          "shell.execute_reply": "2024-04-03T23:28:31.058204Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.shape,test_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPJfUv_lJTJ2",
        "outputId": "ee090a5b-1df4-408d-eb3f-60e2f9b34bb6",
        "execution": {
          "iopub.status.busy": "2024-04-03T23:28:46.019533Z",
          "iopub.execute_input": "2024-04-03T23:28:46.020718Z",
          "iopub.status.idle": "2024-04-03T23:28:46.02835Z",
          "shell.execute_reply.started": "2024-04-03T23:28:46.020661Z",
          "shell.execute_reply": "2024-04-03T23:28:46.027413Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 7,
          "output_type": "execute_result",
          "data": {
            "text/plain": "((7049, 31), (1783, 2))"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.columns"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-03T23:28:48.752884Z",
          "iopub.execute_input": "2024-04-03T23:28:48.753625Z",
          "iopub.status.idle": "2024-04-03T23:28:48.762402Z",
          "shell.execute_reply.started": "2024-04-03T23:28:48.753586Z",
          "shell.execute_reply": "2024-04-03T23:28:48.760631Z"
        },
        "trusted": true,
        "id": "sZ80kt92bUt3",
        "outputId": "3385baf5-ffb0-462f-f637-283ef952c325"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 8,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Index(['left_eye_center_x', 'left_eye_center_y', 'right_eye_center_x',\n       'right_eye_center_y', 'left_eye_inner_corner_x',\n       'left_eye_inner_corner_y', 'left_eye_outer_corner_x',\n       'left_eye_outer_corner_y', 'right_eye_inner_corner_x',\n       'right_eye_inner_corner_y', 'right_eye_outer_corner_x',\n       'right_eye_outer_corner_y', 'left_eyebrow_inner_end_x',\n       'left_eyebrow_inner_end_y', 'left_eyebrow_outer_end_x',\n       'left_eyebrow_outer_end_y', 'right_eyebrow_inner_end_x',\n       'right_eyebrow_inner_end_y', 'right_eyebrow_outer_end_x',\n       'right_eyebrow_outer_end_y', 'nose_tip_x', 'nose_tip_y',\n       'mouth_left_corner_x', 'mouth_left_corner_y', 'mouth_right_corner_x',\n       'mouth_right_corner_y', 'mouth_center_top_lip_x',\n       'mouth_center_top_lip_y', 'mouth_center_bottom_lip_x',\n       'mouth_center_bottom_lip_y', 'Image'],\n      dtype='object')"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the image data and keypoint coordinates\n",
        "images = train_data['Image'].apply(lambda x: np.array(x.split(' '), dtype=int))"
      ],
      "metadata": {
        "id": "a8APX-7q6OfL",
        "execution": {
          "iopub.status.busy": "2024-04-03T23:34:51.798109Z",
          "iopub.execute_input": "2024-04-03T23:34:51.798559Z",
          "iopub.status.idle": "2024-04-03T23:35:05.834425Z",
          "shell.execute_reply.started": "2024-04-03T23:34:51.798529Z",
          "shell.execute_reply": "2024-04-03T23:35:05.832939Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "null_counts=train_data.isna().sum()\n",
        "# null_counts"
      ],
      "metadata": {
        "id": "7TU5JDlWQBJw",
        "execution": {
          "iopub.status.busy": "2024-04-03T23:35:07.844598Z",
          "iopub.execute_input": "2024-04-03T23:35:07.845049Z",
          "iopub.status.idle": "2024-04-03T23:35:07.855892Z",
          "shell.execute_reply.started": "2024-04-03T23:35:07.845009Z",
          "shell.execute_reply": "2024-04-03T23:35:07.853998Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "non_much_Null_values=null_counts.index\n",
        "non_much_Null_values = [col for col in non_much_Null_values if col != 'Image']\n",
        "# non_much_Null_values"
      ],
      "metadata": {
        "id": "FqcVlpCLTvO3",
        "execution": {
          "iopub.status.busy": "2024-04-03T23:35:11.032914Z",
          "iopub.execute_input": "2024-04-03T23:35:11.033341Z",
          "iopub.status.idle": "2024-04-03T23:35:11.040172Z",
          "shell.execute_reply.started": "2024-04-03T23:35:11.033309Z",
          "shell.execute_reply": "2024-04-03T23:35:11.038724Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for feature in non_much_Null_values:\n",
        "    median_value = train_data[feature].median()\n",
        "    train_data[feature].fillna(median_value, inplace=True)"
      ],
      "metadata": {
        "id": "FsKtzYDSLfqo",
        "execution": {
          "iopub.status.busy": "2024-04-03T23:35:17.674767Z",
          "iopub.execute_input": "2024-04-03T23:35:17.675259Z",
          "iopub.status.idle": "2024-04-03T23:35:17.705921Z",
          "shell.execute_reply.started": "2024-04-03T23:35:17.675221Z",
          "shell.execute_reply": "2024-04-03T23:35:17.704666Z"
        },
        "trusted": true,
        "outputId": "d3a2957d-2e07-4b46-afd7-20b14fe971f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_33/1613402553.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  train_data[feature].fillna(median_value, inplace=True)\n/tmp/ipykernel_33/1613402553.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  train_data[feature].fillna(median_value, inplace=True)\n/tmp/ipykernel_33/1613402553.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  train_data[feature].fillna(median_value, inplace=True)\n/tmp/ipykernel_33/1613402553.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  train_data[feature].fillna(median_value, inplace=True)\n/tmp/ipykernel_33/1613402553.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  train_data[feature].fillna(median_value, inplace=True)\n/tmp/ipykernel_33/1613402553.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  train_data[feature].fillna(median_value, inplace=True)\n/tmp/ipykernel_33/1613402553.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  train_data[feature].fillna(median_value, inplace=True)\n/tmp/ipykernel_33/1613402553.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  train_data[feature].fillna(median_value, inplace=True)\n/tmp/ipykernel_33/1613402553.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  train_data[feature].fillna(median_value, inplace=True)\n/tmp/ipykernel_33/1613402553.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  train_data[feature].fillna(median_value, inplace=True)\n/tmp/ipykernel_33/1613402553.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  train_data[feature].fillna(median_value, inplace=True)\n/tmp/ipykernel_33/1613402553.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  train_data[feature].fillna(median_value, inplace=True)\n/tmp/ipykernel_33/1613402553.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  train_data[feature].fillna(median_value, inplace=True)\n/tmp/ipykernel_33/1613402553.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  train_data[feature].fillna(median_value, inplace=True)\n/tmp/ipykernel_33/1613402553.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  train_data[feature].fillna(median_value, inplace=True)\n/tmp/ipykernel_33/1613402553.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  train_data[feature].fillna(median_value, inplace=True)\n/tmp/ipykernel_33/1613402553.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  train_data[feature].fillna(median_value, inplace=True)\n/tmp/ipykernel_33/1613402553.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  train_data[feature].fillna(median_value, inplace=True)\n/tmp/ipykernel_33/1613402553.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  train_data[feature].fillna(median_value, inplace=True)\n/tmp/ipykernel_33/1613402553.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  train_data[feature].fillna(median_value, inplace=True)\n/tmp/ipykernel_33/1613402553.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  train_data[feature].fillna(median_value, inplace=True)\n/tmp/ipykernel_33/1613402553.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  train_data[feature].fillna(median_value, inplace=True)\n/tmp/ipykernel_33/1613402553.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  train_data[feature].fillna(median_value, inplace=True)\n/tmp/ipykernel_33/1613402553.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  train_data[feature].fillna(median_value, inplace=True)\n/tmp/ipykernel_33/1613402553.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  train_data[feature].fillna(median_value, inplace=True)\n/tmp/ipykernel_33/1613402553.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  train_data[feature].fillna(median_value, inplace=True)\n/tmp/ipykernel_33/1613402553.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  train_data[feature].fillna(median_value, inplace=True)\n/tmp/ipykernel_33/1613402553.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  train_data[feature].fillna(median_value, inplace=True)\n/tmp/ipykernel_33/1613402553.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  train_data[feature].fillna(median_value, inplace=True)\n/tmp/ipykernel_33/1613402553.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  train_data[feature].fillna(median_value, inplace=True)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as A\n",
        "\n",
        "# Define the augmentation transforms\n",
        "transforms = A.Compose([\n",
        "    A.RandomRotate90(),\n",
        "    A.Flip(),\n",
        "    A.Transpose(),\n",
        "    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.5),\n",
        "    A.GaussianBlur(blur_limit=(3, 7), p=0.5),\n",
        "    A.Normalize()\n",
        "])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-03T23:36:48.86039Z",
          "iopub.execute_input": "2024-04-03T23:36:48.860891Z",
          "iopub.status.idle": "2024-04-03T23:36:49.766419Z",
          "shell.execute_reply.started": "2024-04-03T23:36:48.860859Z",
          "shell.execute_reply": "2024-04-03T23:36:49.765085Z"
        },
        "trusted": true,
        "id": "Snpm57OabUt5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new DataFrame to store the augmented data\n",
        "augmented_data = pd.DataFrame(columns=train_data.columns)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-03T23:46:36.48965Z",
          "iopub.execute_input": "2024-04-03T23:46:36.490106Z",
          "iopub.status.idle": "2024-04-03T23:46:36.499227Z",
          "shell.execute_reply.started": "2024-04-03T23:46:36.490069Z",
          "shell.execute_reply": "2024-04-03T23:46:36.49764Z"
        },
        "trusted": true,
        "id": "tb0oB5PZbUt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_str=train_data['Image'][0]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-03T23:53:10.791849Z",
          "iopub.execute_input": "2024-04-03T23:53:10.792346Z",
          "iopub.status.idle": "2024-04-03T23:53:10.797423Z",
          "shell.execute_reply.started": "2024-04-03T23:53:10.792303Z",
          "shell.execute_reply": "2024-04-03T23:53:10.796441Z"
        },
        "trusted": true,
        "id": "r9PHz3sxbUt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=np.array([int(x) for x in image_str.split()])\n",
        "x"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-03T23:53:12.66766Z",
          "iopub.execute_input": "2024-04-03T23:53:12.668155Z",
          "iopub.status.idle": "2024-04-03T23:53:12.68162Z",
          "shell.execute_reply.started": "2024-04-03T23:53:12.668123Z",
          "shell.execute_reply": "2024-04-03T23:53:12.680215Z"
        },
        "trusted": true,
        "id": "M5rQqCxMbUt6",
        "outputId": "4b7f985a-278d-40f3-a8bf-010f4498887b"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 43,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([238, 236, 237, ...,  70,  75,  90])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=x.reshape(96,96,1)\n",
        "x"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-03T23:54:39.232636Z",
          "iopub.execute_input": "2024-04-03T23:54:39.23313Z",
          "iopub.status.idle": "2024-04-03T23:54:39.2434Z",
          "shell.execute_reply.started": "2024-04-03T23:54:39.233097Z",
          "shell.execute_reply": "2024-04-03T23:54:39.241897Z"
        },
        "trusted": true,
        "id": "MWiikorRbUt6",
        "outputId": "7cb13f4c-4c06-4e80-91f2-bc74bb9ddcb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 44,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([[[238],\n        [236],\n        [237],\n        ...,\n        [250],\n        [250],\n        [250]],\n\n       [[235],\n        [238],\n        [236],\n        ...,\n        [249],\n        [250],\n        [251]],\n\n       [[237],\n        [236],\n        [237],\n        ...,\n        [251],\n        [251],\n        [250]],\n\n       ...,\n\n       [[186],\n        [183],\n        [181],\n        ...,\n        [ 52],\n        [ 57],\n        [ 60]],\n\n       [[189],\n        [188],\n        [207],\n        ...,\n        [ 61],\n        [ 69],\n        [ 78]],\n\n       [[191],\n        [184],\n        [184],\n        ...,\n        [ 70],\n        [ 75],\n        [ 90]]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the image and keypoint data\n",
        "for index, row in train_data.iterrows():\n",
        "    image_str = row['Image']\n",
        "    image = np.array([int(x) for x in image_str.split()])\n",
        "    image = image.reshape(96, 96, 1)\n",
        "    keypoints = np.array([\n",
        "        (row['left_eye_center_x'], row['left_eye_center_y'], 0, 1),\n",
        "        (row['right_eye_center_x'], row['right_eye_center_y'], 0, 1),\n",
        "        (row['left_eye_inner_corner_x'], row['left_eye_inner_corner_y'], 0, 1),\n",
        "        (row['left_eye_outer_corner_x'], row['left_eye_outer_corner_y'], 0, 1),\n",
        "        (row['right_eye_inner_corner_x'], row['right_eye_inner_corner_y'], 0, 1),\n",
        "        (row['right_eye_outer_corner_x'], row['right_eye_outer_corner_y'], 0, 1),\n",
        "        (row['left_eyebrow_inner_end_x'], row['left_eyebrow_inner_end_y'], 0, 1),\n",
        "        (row['left_eyebrow_outer_end_x'], row['left_eyebrow_outer_end_y'], 0, 1),\n",
        "        (row['right_eyebrow_inner_end_x'], row['right_eyebrow_inner_end_y'], 0, 1),\n",
        "        (row['right_eyebrow_outer_end_x'], row['right_eyebrow_outer_end_y'], 0, 1),\n",
        "        (row['nose_tip_x'], row['nose_tip_y'], 0, 1),\n",
        "        (row['mouth_left_corner_x'], row['mouth_left_corner_y'], 0, 1),\n",
        "        (row['mouth_right_corner_x'], row['mouth_right_corner_y'], 0, 1),\n",
        "        (row['mouth_center_top_lip_x'], row['mouth_center_top_lip_y'], 0, 1),\n",
        "        (row['mouth_center_bottom_lip_x'], row['mouth_center_bottom_lip_y'], 0, 1)\n",
        "    ])\n",
        "\n",
        "    # Apply the augmentation transforms\n",
        "    augmented = transforms(image=image, keypoints=keypoints)\n",
        "    augmented_image = augmented['image']\n",
        "    augmented_keypoints = augmented['keypoints']\n",
        "\n",
        "    # Create a new row in the augmented_data DataFrame\n",
        "    new_row = {\n",
        "        'left_eye_center_x': augmented_keypoints[0][0],\n",
        "        'left_eye_center_y': augmented_keypoints[0][1],\n",
        "        'right_eye_center_x': augmented_keypoints[1][0],\n",
        "        'right_eye_center_y': augmented_keypoints[1][1],\n",
        "        'left_eye_inner_corner_x': augmented_keypoints[2][0],\n",
        "        'left_eye_inner_corner_y': augmented_keypoints[2][1],\n",
        "        'left_eye_outer_corner_x': augmented_keypoints[3][0],\n",
        "        'left_eye_outer_corner_y': augmented_keypoints[3][1],\n",
        "        'right_eye_inner_corner_x': augmented_keypoints[4][0],\n",
        "        'right_eye_inner_corner_y': augmented_keypoints[4][1],\n",
        "        'right_eye_outer_corner_x': augmented_keypoints[5][0],\n",
        "        'right_eye_outer_corner_y': augmented_keypoints[5][1],\n",
        "        'left_eyebrow_inner_end_x': augmented_keypoints[6][0],\n",
        "        'left_eyebrow_inner_end_y': augmented_keypoints[6][1],\n",
        "        'left_eyebrow_outer_end_x': augmented_keypoints[7][0],\n",
        "        'left_eyebrow_outer_end_y': augmented_keypoints[7][1],\n",
        "        'right_eyebrow_inner_end_x': augmented_keypoints[8][0],\n",
        "        'right_eyebrow_inner_end_y': augmented_keypoints[8][1],\n",
        "        'right_eyebrow_outer_end_x': augmented_keypoints[9][0],\n",
        "        'right_eyebrow_outer_end_y': augmented_keypoints[9][1],\n",
        "        'nose_tip_x': augmented_keypoints[10][0],\n",
        "        'nose_tip_y': augmented_keypoints[10][1],\n",
        "        'mouth_left_corner_x': augmented_keypoints[11][0],\n",
        "        'mouth_left_corner_y': augmented_keypoints[11][1],\n",
        "        'mouth_right_corner_x': augmented_keypoints[12][0],\n",
        "        'mouth_right_corner_y': augmented_keypoints[12][1],\n",
        "        'mouth_center_top_lip_x': augmented_keypoints[13][0],\n",
        "        'mouth_center_top_lip_y': augmented_keypoints[13][1],\n",
        "        'mouth_center_bottom_lip_x': augmented_keypoints[14][0],\n",
        "        'mouth_center_bottom_lip_y': augmented_keypoints[14][1],\n",
        "        'Image': augmented_image\n",
        "    }\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-04T00:04:39.996676Z",
          "iopub.execute_input": "2024-04-04T00:04:39.997134Z",
          "iopub.status.idle": "2024-04-04T00:04:40.295907Z",
          "shell.execute_reply.started": "2024-04-04T00:04:39.997102Z",
          "shell.execute_reply": "2024-04-04T00:04:40.293789Z"
        },
        "trusted": true,
        "id": "cjPUovnlbUt7",
        "outputId": "62a67f32-bafd-423b-e673-aac2d7e0ae31"
      },
      "execution_count": null,
      "outputs": [
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[52], line 25\u001b[0m\n\u001b[1;32m      6\u001b[0m keypoints \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\n\u001b[1;32m      7\u001b[0m     (row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft_eye_center_x\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft_eye_center_y\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m      8\u001b[0m     (row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mright_eye_center_x\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mright_eye_center_y\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     (row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouth_center_bottom_lip_x\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouth_center_bottom_lip_y\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     22\u001b[0m ])\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Apply the augmentation transforms\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m augmented \u001b[38;5;241m=\u001b[39m \u001b[43mtransforms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeypoints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeypoints\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m augmented_image \u001b[38;5;241m=\u001b[39m augmented[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     27\u001b[0m augmented_keypoints \u001b[38;5;241m=\u001b[39m augmented[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeypoints\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/albumentations/core/composition.py:213\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, force_apply, *args, **data)\u001b[0m\n\u001b[1;32m    210\u001b[0m     p\u001b[38;5;241m.\u001b[39mpreprocess(data)\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m transforms:\n\u001b[0;32m--> 213\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check_each_transform:\n\u001b[1;32m    216\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_data_post_transform(data)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/albumentations/core/transforms_interface.py:119\u001b[0m, in \u001b[0;36mBasicTransform.__call__\u001b[0;34m(self, force_apply, *args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m             warn(\n\u001b[1;32m    115\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_class_fullname() \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m could work incorrectly in ReplayMode for other input data\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    116\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m because its\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m params depend on targets.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    117\u001b[0m             )\n\u001b[1;32m    118\u001b[0m         kwargs[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_key][\u001b[38;5;28mid\u001b[39m(\u001b[38;5;28mself\u001b[39m)] \u001b[38;5;241m=\u001b[39m deepcopy(params)\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_with_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m kwargs\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/albumentations/core/transforms_interface.py:132\u001b[0m, in \u001b[0;36mBasicTransform.apply_with_params\u001b[0;34m(self, params, *args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m     target_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_target_function(key)\n\u001b[1;32m    131\u001b[0m     target_dependencies \u001b[38;5;241m=\u001b[39m {k: kwargs[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_dependence\u001b[38;5;241m.\u001b[39mget(key, [])}\n\u001b[0;32m--> 132\u001b[0m     res[key] \u001b[38;5;241m=\u001b[39m \u001b[43mtarget_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtarget_dependencies\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    134\u001b[0m     res[key] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/albumentations/augmentations/geometric/transforms.py:128\u001b[0m, in \u001b[0;36mShiftScaleRotate.apply\u001b[0;34m(self, img, angle, scale, dx, dy, interpolation, **params)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    120\u001b[0m     img: np\u001b[38;5;241m.\u001b[39mndarray,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams: Any,\n\u001b[1;32m    127\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshift_scale_rotate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mangle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mborder_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/albumentations/augmentations/utils.py:122\u001b[0m, in \u001b[0;36mpreserve_channel_dim.<locals>.wrapped_function\u001b[0;34m(img, *args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_function\u001b[39m(img: np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;241m*\u001b[39margs: P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m    121\u001b[0m     shape \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m--> 122\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(shape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m shape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(result\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    124\u001b[0m         result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(result, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/albumentations/augmentations/geometric/functional.py:240\u001b[0m, in \u001b[0;36mshift_scale_rotate\u001b[0;34m(img, angle, scale, dx, dy, interpolation, border_mode, value)\u001b[0m\n\u001b[1;32m    235\u001b[0m matrix[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m dy \u001b[38;5;241m*\u001b[39m height\n\u001b[1;32m    237\u001b[0m warp_affine_fn \u001b[38;5;241m=\u001b[39m _maybe_process_in_chunks(\n\u001b[1;32m    238\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mwarpAffine, M\u001b[38;5;241m=\u001b[39mmatrix, dsize\u001b[38;5;241m=\u001b[39m(width, height), flags\u001b[38;5;241m=\u001b[39minterpolation, borderMode\u001b[38;5;241m=\u001b[39mborder_mode, borderValue\u001b[38;5;241m=\u001b[39mvalue\n\u001b[1;32m    239\u001b[0m )\n\u001b[0;32m--> 240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwarp_affine_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/albumentations/augmentations/utils.py:208\u001b[0m, in \u001b[0;36m_maybe_process_in_chunks.<locals>.__process_fn\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m    206\u001b[0m     img \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdstack(chunks)\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 208\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.9.0) /io/opencv/modules/imgproc/src/imgwarp.cpp:1820: error: (-215:Assertion failed) ifunc != 0 in function 'remap'\n"
          ],
          "ename": "error",
          "evalue": "OpenCV(4.9.0) /io/opencv/modules/imgproc/src/imgwarp.cpp:1820: error: (-215:Assertion failed) ifunc != 0 in function 'remap'\n",
          "output_type": "error"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the augmentation transforms to the data\n",
        "for index, row in train_data.iterrows():\n",
        "    # Extract the image and keypoint data\n",
        "    image_str = row['Image']\n",
        "    image = np.array([int(x) for x in image_str.split()])\n",
        "    image = image.reshape(96, 96, 1)\n",
        "    keypoints = np.array([\n",
        "    row['left_eye_center_x'], row['left_eye_center_y'],\n",
        "    row['right_eye_center_x'], row['right_eye_center_y'],\n",
        "    row['left_eye_inner_corner_x'], row['left_eye_inner_corner_y'],\n",
        "    row['left_eye_outer_corner_x'], row['left_eye_outer_corner_y'],\n",
        "    row['right_eye_inner_corner_x'], row['right_eye_inner_corner_y'],\n",
        "    row['right_eye_outer_corner_x'], row['right_eye_outer_corner_y'],\n",
        "    row['left_eyebrow_inner_end_x'], row['left_eyebrow_inner_end_y'],\n",
        "    row['left_eyebrow_outer_end_x'], row['left_eyebrow_outer_end_y'],\n",
        "    row['right_eyebrow_inner_end_x'], row['right_eyebrow_inner_end_y'],\n",
        "    row['right_eyebrow_outer_end_x'], row['right_eyebrow_outer_end_y'],\n",
        "    row['nose_tip_x'], row['nose_tip_y'],\n",
        "    row['mouth_left_corner_x'], row['mouth_left_corner_y'],\n",
        "    row['mouth_right_corner_x'], row['mouth_right_corner_y'],\n",
        "    row['mouth_center_top_lip_x'], row['mouth_center_top_lip_y'],\n",
        "    row['mouth_center_bottom_lip_x'], row['mouth_center_bottom_lip_y']\n",
        "    ]).reshape(-1, 2)\n",
        "    # Apply the augmentation transforms\n",
        "    augmented = transforms(image=image, keypoints=keypoints)\n",
        "    augmented_image = augmented['image']\n",
        "    augmented_keypoints = augmented['keypoints']\n",
        "\n",
        "    # Create a new row in the augmented_data DataFrame\n",
        "    new_row = {\n",
        "    'left_eye_center_x': augmented_keypoints[0],\n",
        "    'left_eye_center_y': augmented_keypoints[1],\n",
        "    'right_eye_center_x': augmented_keypoints[2],\n",
        "    'right_eye_center_y': augmented_keypoints[3],\n",
        "    'left_eye_inner_corner_x': augmented_keypoints[4],\n",
        "    'left_eye_inner_corner_y': augmented_keypoints[5],\n",
        "    'left_eye_outer_corner_x': augmented_keypoints[6],\n",
        "    'left_eye_outer_corner_y': augmented_keypoints[7],\n",
        "    'right_eye_inner_corner_x': augmented_keypoints[8],\n",
        "    'right_eye_inner_corner_y': augmented_keypoints[9],\n",
        "    'right_eye_outer_corner_x': augmented_keypoints[10],\n",
        "    'right_eye_outer_corner_y': augmented_keypoints[11],\n",
        "    'left_eyebrow_inner_end_x': augmented_keypoints[12],\n",
        "    'left_eyebrow_inner_end_y': augmented_keypoints[13],\n",
        "    'left_eyebrow_outer_end_x': augmented_keypoints[14],\n",
        "    'left_eyebrow_outer_end_y': augmented_keypoints[15],\n",
        "    'right_eyebrow_inner_end_x': augmented_keypoints[16],\n",
        "    'right_eyebrow_inner_end_y': augmented_keypoints[17],\n",
        "    'right_eyebrow_outer_end_x': augmented_keypoints[18],\n",
        "    'right_eyebrow_outer_end_y': augmented_keypoints[19],\n",
        "    'nose_tip_x': augmented_keypoints[20],\n",
        "    'nose_tip_y': augmented_keypoints[21],\n",
        "    'mouth_left_corner_x': augmented_keypoints[22],\n",
        "    'mouth_left_corner_y': augmented_keypoints[23],\n",
        "    'mouth_right_corner_x': augmented_keypoints[24],\n",
        "    'mouth_right_corner_y': augmented_keypoints[25],\n",
        "    'mouth_center_top_lip_x': augmented_keypoints[26],\n",
        "    'mouth_center_top_lip_y': augmented_keypoints[27],\n",
        "    'mouth_center_bottom_lip_x': augmented_keypoints[28],\n",
        "    'mouth_center_bottom_lip_y': augmented_keypoints[29],\n",
        "    'Image': augmented_image\n",
        "    }\n",
        "\n",
        "    augmented_data = augmented_data.append(new_row, ignore_index=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-04T00:02:08.572635Z",
          "iopub.execute_input": "2024-04-04T00:02:08.573139Z",
          "iopub.status.idle": "2024-04-04T00:02:09.164778Z",
          "shell.execute_reply.started": "2024-04-04T00:02:08.573104Z",
          "shell.execute_reply": "2024-04-04T00:02:09.162986Z"
        },
        "trusted": true,
        "id": "vCmD8vatbUt7",
        "outputId": "d52bda81-9bda-4116-acbb-c348446b94df"
      },
      "execution_count": null,
      "outputs": [
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[51], line 25\u001b[0m\n\u001b[1;32m      7\u001b[0m keypoints \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\n\u001b[1;32m      8\u001b[0m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft_eye_center_x\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft_eye_center_y\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      9\u001b[0m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mright_eye_center_x\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mright_eye_center_y\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouth_center_bottom_lip_x\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmouth_center_bottom_lip_y\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     23\u001b[0m ])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Apply the augmentation transforms\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m augmented \u001b[38;5;241m=\u001b[39m \u001b[43mtransforms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeypoints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeypoints\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m augmented_image \u001b[38;5;241m=\u001b[39m augmented[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     27\u001b[0m augmented_keypoints \u001b[38;5;241m=\u001b[39m augmented[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeypoints\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/albumentations/core/composition.py:213\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, force_apply, *args, **data)\u001b[0m\n\u001b[1;32m    210\u001b[0m     p\u001b[38;5;241m.\u001b[39mpreprocess(data)\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m transforms:\n\u001b[0;32m--> 213\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check_each_transform:\n\u001b[1;32m    216\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_data_post_transform(data)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/albumentations/core/transforms_interface.py:119\u001b[0m, in \u001b[0;36mBasicTransform.__call__\u001b[0;34m(self, force_apply, *args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m             warn(\n\u001b[1;32m    115\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_class_fullname() \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m could work incorrectly in ReplayMode for other input data\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    116\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m because its\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m params depend on targets.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    117\u001b[0m             )\n\u001b[1;32m    118\u001b[0m         kwargs[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_key][\u001b[38;5;28mid\u001b[39m(\u001b[38;5;28mself\u001b[39m)] \u001b[38;5;241m=\u001b[39m deepcopy(params)\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_with_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m kwargs\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/albumentations/core/transforms_interface.py:132\u001b[0m, in \u001b[0;36mBasicTransform.apply_with_params\u001b[0;34m(self, params, *args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m     target_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_target_function(key)\n\u001b[1;32m    131\u001b[0m     target_dependencies \u001b[38;5;241m=\u001b[39m {k: kwargs[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_dependence\u001b[38;5;241m.\u001b[39mget(key, [])}\n\u001b[0;32m--> 132\u001b[0m     res[key] \u001b[38;5;241m=\u001b[39m \u001b[43mtarget_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtarget_dependencies\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    134\u001b[0m     res[key] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/albumentations/core/transforms_interface.py:263\u001b[0m, in \u001b[0;36mDualTransform.apply_to_keypoints\u001b[0;34m(self, keypoints, *args, **params)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_to_keypoints\u001b[39m(\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28mself\u001b[39m, keypoints: Sequence[KeypointType], \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams: Any\n\u001b[1;32m    262\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Sequence[KeypointType]:\n\u001b[0;32m--> 263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    264\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_to_keypoint(cast(KeypointInternalType, \u001b[38;5;28mtuple\u001b[39m(keypoint[:\u001b[38;5;241m4\u001b[39m])), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mtuple\u001b[39m(keypoint[\u001b[38;5;241m4\u001b[39m:])\n\u001b[1;32m    265\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m keypoint \u001b[38;5;129;01min\u001b[39;00m keypoints\n\u001b[1;32m    266\u001b[0m     ]\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/albumentations/core/transforms_interface.py:264\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_to_keypoints\u001b[39m(\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28mself\u001b[39m, keypoints: Sequence[KeypointType], \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams: Any\n\u001b[1;32m    262\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Sequence[KeypointType]:\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m--> 264\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_to_keypoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mKeypointInternalType\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkeypoint\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mtuple\u001b[39m(keypoint[\u001b[38;5;241m4\u001b[39m:])\n\u001b[1;32m    265\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m keypoint \u001b[38;5;129;01min\u001b[39;00m keypoints\n\u001b[1;32m    266\u001b[0m     ]\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/albumentations/augmentations/geometric/transforms.py:1346\u001b[0m, in \u001b[0;36mFlip.apply_to_keypoint\u001b[0;34m(self, keypoint, **params)\u001b[0m\n\u001b[1;32m   1345\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_to_keypoint\u001b[39m(\u001b[38;5;28mself\u001b[39m, keypoint: KeypointInternalType, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m KeypointInternalType:\n\u001b[0;32m-> 1346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeypoint_flip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeypoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/albumentations/augmentations/geometric/functional.py:1057\u001b[0m, in \u001b[0;36mkeypoint_flip\u001b[0;34m(keypoint, d, rows, cols)\u001b[0m\n\u001b[1;32m   1055\u001b[0m     keypoint \u001b[38;5;241m=\u001b[39m keypoint_hflip(keypoint, rows, cols)\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m d \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m-> 1057\u001b[0m     keypoint \u001b[38;5;241m=\u001b[39m \u001b[43mkeypoint_hflip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeypoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1058\u001b[0m     keypoint \u001b[38;5;241m=\u001b[39m keypoint_vflip(keypoint, rows, cols)\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/albumentations/augmentations/utils.py:93\u001b[0m, in \u001b[0;36mangle_2pi_range.<locals>.wrapped_function\u001b[0;34m(keypoint, *args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_function\u001b[39m(keypoint: KeypointInternalType, \u001b[38;5;241m*\u001b[39margs: P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m KeypointInternalType:\n\u001b[0;32m---> 93\u001b[0m     (x, y, a, s) \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeypoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m4\u001b[39m]\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (x, y, angle_to_2pi_range(a), s)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/albumentations/augmentations/geometric/functional.py:1028\u001b[0m, in \u001b[0;36mkeypoint_hflip\u001b[0;34m(keypoint, rows, cols)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;129m@angle_2pi_range\u001b[39m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mkeypoint_hflip\u001b[39m(keypoint: KeypointInternalType, rows: \u001b[38;5;28mint\u001b[39m, cols: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m KeypointInternalType:\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Flip a keypoint horizontally around the y-axis.\u001b[39;00m\n\u001b[1;32m   1018\u001b[0m \n\u001b[1;32m   1019\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1026\u001b[0m \n\u001b[1;32m   1027\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1028\u001b[0m     x, y, angle, scale \u001b[38;5;241m=\u001b[39m keypoint[:\u001b[38;5;241m4\u001b[39m]\n\u001b[1;32m   1029\u001b[0m     angle \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39mpi \u001b[38;5;241m-\u001b[39m angle\n\u001b[1;32m   1030\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (cols \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m x, y, angle, scale\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 2)"
          ],
          "ename": "ValueError",
          "evalue": "not enough values to unpack (expected 4, got 2)",
          "output_type": "error"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Save the augmented data to a new file\n",
        "augmented_data.to_csv('augmented_train_data.csv', index=False)\n"
      ],
      "metadata": {
        "id": "yoYMYj0dbUt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keypoints = train_data.drop('Image', axis=1)"
      ],
      "metadata": {
        "id": "vVBZ3osyV9bM",
        "execution": {
          "iopub.status.busy": "2024-04-01T23:28:45.782215Z",
          "iopub.execute_input": "2024-04-01T23:28:45.78257Z",
          "iopub.status.idle": "2024-04-01T23:28:45.794835Z",
          "shell.execute_reply.started": "2024-04-01T23:28:45.782531Z",
          "shell.execute_reply": "2024-04-01T23:28:45.793795Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(images, keypoints, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "boQUiIqlM0vn",
        "execution": {
          "iopub.status.busy": "2024-04-01T23:28:45.79643Z",
          "iopub.execute_input": "2024-04-01T23:28:45.797499Z",
          "iopub.status.idle": "2024-04-01T23:28:45.811086Z",
          "shell.execute_reply.started": "2024-04-01T23:28:45.797429Z",
          "shell.execute_reply": "2024-04-01T23:28:45.809803Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape the image data\n",
        "X_train = np.array([x.reshape(96, 96, 1) for x in X_train])\n",
        "X_val = np.array([x.reshape(96, 96, 1) for x in X_val])"
      ],
      "metadata": {
        "id": "mi4KWeeJ6Rx2",
        "execution": {
          "iopub.status.busy": "2024-04-01T23:28:45.813392Z",
          "iopub.execute_input": "2024-04-01T23:28:45.813857Z",
          "iopub.status.idle": "2024-04-01T23:28:46.083182Z",
          "shell.execute_reply.started": "2024-04-01T23:28:45.813812Z",
          "shell.execute_reply": "2024-04-01T23:28:46.082206Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "U9utdUVml2cc",
        "execution": {
          "iopub.status.busy": "2024-04-01T23:28:46.084621Z",
          "iopub.execute_input": "2024-04-01T23:28:46.084939Z",
          "iopub.status.idle": "2024-04-01T23:28:46.09252Z",
          "shell.execute_reply.started": "2024-04-01T23:28:46.084913Z",
          "shell.execute_reply": "2024-04-01T23:28:46.091176Z"
        },
        "trusted": true,
        "outputId": "9b076eb6-97ba-43fb-e79a-3c6f9aea40bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 12,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(5639, 96, 96, 1)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf_tensor = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
        "# Assuming X_train is your grayscale image dataset with shape (num_images, 96, 96, 1)\n",
        "X_train_rgb = tf.image.grayscale_to_rgb(tf_tensor)"
      ],
      "metadata": {
        "id": "2T6vCEf6i_Jj",
        "execution": {
          "iopub.status.busy": "2024-04-01T23:28:46.093895Z",
          "iopub.execute_input": "2024-04-01T23:28:46.094329Z",
          "iopub.status.idle": "2024-04-01T23:28:47.008282Z",
          "shell.execute_reply.started": "2024-04-01T23:28:46.094287Z",
          "shell.execute_reply": "2024-04-01T23:28:47.007389Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_rgb.shape"
      ],
      "metadata": {
        "id": "g68Fd0BLk6RV",
        "execution": {
          "iopub.status.busy": "2024-04-01T23:28:47.009175Z",
          "iopub.execute_input": "2024-04-01T23:28:47.009516Z",
          "iopub.status.idle": "2024-04-01T23:28:47.015924Z",
          "shell.execute_reply.started": "2024-04-01T23:28:47.009488Z",
          "shell.execute_reply": "2024-04-01T23:28:47.014873Z"
        },
        "trusted": true,
        "outputId": "b74dc1ae-e87e-4b66-c839-deb048b30ca3"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 14,
          "output_type": "execute_result",
          "data": {
            "text/plain": "TensorShape([5639, 96, 96, 3])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import EfficientNetV2S,ResNet50\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "PAFNxIAE2lHD",
        "execution": {
          "iopub.status.busy": "2024-04-01T23:28:47.02179Z",
          "iopub.execute_input": "2024-04-01T23:28:47.022352Z",
          "iopub.status.idle": "2024-04-01T23:28:47.031956Z",
          "shell.execute_reply.started": "2024-04-01T23:28:47.02232Z",
          "shell.execute_reply": "2024-04-01T23:28:47.030909Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import VGG19\n",
        "\n",
        "vgg19_model = VGG19(weights='imagenet', include_top=False, input_shape=(96, 96, 3))\n",
        "for layer in vgg19_model.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-01T23:28:47.033442Z",
          "iopub.execute_input": "2024-04-01T23:28:47.034491Z",
          "iopub.status.idle": "2024-04-01T23:28:50.280709Z",
          "shell.execute_reply.started": "2024-04-01T23:28:47.034458Z",
          "shell.execute_reply": "2024-04-01T23:28:50.279603Z"
        },
        "trusted": true,
        "id": "LkkGtb97bUt8",
        "outputId": "8addc13c-08b2-42d5-8a79-33a847ff81e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m80134624/80134624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import DenseNet121\n",
        "\n",
        "densenet_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(96, 96, 3))\n",
        "for layer in densenet_model.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-01T23:28:50.282332Z",
          "iopub.execute_input": "2024-04-01T23:28:50.283346Z",
          "iopub.status.idle": "2024-04-01T23:28:55.140651Z",
          "shell.execute_reply.started": "2024-04-01T23:28:50.283287Z",
          "shell.execute_reply": "2024-04-01T23:28:55.13953Z"
        },
        "trusted": true,
        "id": "69b3o95YbUt8",
        "outputId": "e385f6ab-1fa5-4104-f83d-32a933da8d24"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m29084464/29084464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import MobileNet\n",
        "mobilenet_model = MobileNet(weights='imagenet', include_top=False, input_shape=(96, 96, 3))\n",
        "for layer in mobilenet_model.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-01T23:28:55.142192Z",
          "iopub.execute_input": "2024-04-01T23:28:55.142829Z",
          "iopub.status.idle": "2024-04-01T23:28:56.978358Z",
          "shell.execute_reply.started": "2024-04-01T23:28:55.142797Z",
          "shell.execute_reply": "2024-04-01T23:28:56.977138Z"
        },
        "trusted": true,
        "id": "tcOimC3_bUt8",
        "outputId": "9a5ba064-679c-4709-c57e-1b1ae67d3a36"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_33/1187213090.py:2: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n  mobilenet_model = MobileNet(weights='imagenet', include_top=False, input_shape=(96, 96, 3))\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5\n\u001b[1m17225924/17225924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.efficientnet import EfficientNetB4\n",
        "efficientnet_model = EfficientNetB4(weights='imagenet', include_top=False, input_shape=(96, 96, 3))\n",
        "for layer in efficientnet_model.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-01T23:28:56.980184Z",
          "iopub.execute_input": "2024-04-01T23:28:56.980606Z",
          "iopub.status.idle": "2024-04-01T23:29:02.942516Z",
          "shell.execute_reply.started": "2024-04-01T23:28:56.980574Z",
          "shell.execute_reply": "2024-04-01T23:29:02.941124Z"
        },
        "trusted": true,
        "id": "_FRxm8d3bUt8",
        "outputId": "aacf5a0f-e3d7-46bf-d301-21419cea57da"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb4_notop.h5\n\u001b[1m71686520/71686520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "model = ResNet50(include_top=True, weights='imagenet', input_shape=(224, 224, 3))\n",
        "resnext_model = ResNet50(weights='imagenet', include_top=False, input_shape=(96, 96, 3))\n",
        "for layer in resnext_model.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-01T23:29:02.94433Z",
          "iopub.execute_input": "2024-04-01T23:29:02.944706Z",
          "iopub.status.idle": "2024-04-01T23:29:12.205973Z",
          "shell.execute_reply.started": "2024-04-01T23:29:02.944675Z",
          "shell.execute_reply": "2024-04-01T23:29:12.204789Z"
        },
        "trusted": true,
        "id": "JvE7t8QUbUt9",
        "outputId": "ce7be4e2-565d-402e-ede9-4dcdf0cd80b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n\u001b[1m102967424/102967424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def trainfun(model):\n",
        "    model = models.Sequential([\n",
        "        model,\n",
        "        layers.GlobalAveragePooling2D(),\n",
        "        layers.Dense(512, activation='relu'),\n",
        "        layers.Dropout(0.1),\n",
        "        layers.Dense(30)  # Assuming a binary classification problem\n",
        "    ])\n",
        "    model.compile(optimizer='adam',\n",
        "              loss='mean_squared_error',\n",
        "              metrics=['mae'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "cuupuRDN29AV",
        "execution": {
          "iopub.status.busy": "2024-04-01T23:29:12.207432Z",
          "iopub.execute_input": "2024-04-01T23:29:12.207794Z",
          "iopub.status.idle": "2024-04-01T23:29:12.215008Z",
          "shell.execute_reply.started": "2024-04-01T23:29:12.207763Z",
          "shell.execute_reply": "2024-04-01T23:29:12.213707Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=trainfun(resnext_model)\n",
        "model.fit(X_train_rgb,y_train,epochs =5,batch_size = 256,validation_split = 0.2)"
      ],
      "metadata": {
        "id": "oNWSdfOxa2DS",
        "execution": {
          "iopub.status.busy": "2024-04-01T23:29:12.216219Z",
          "iopub.execute_input": "2024-04-01T23:29:12.216586Z",
          "iopub.status.idle": "2024-04-01T23:41:11.129098Z",
          "shell.execute_reply.started": "2024-04-01T23:29:12.216544Z",
          "shell.execute_reply": "2024-04-01T23:41:11.127979Z"
        },
        "trusted": true,
        "outputId": "ebfc5f65-c056-4dfd-91eb-e53b1251fda0"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/5\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 5s/step - loss: 1484.4110 - mae: 32.7555 - val_loss: 193.4441 - val_mae: 9.5057\nEpoch 2/5\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 5s/step - loss: 148.9010 - mae: 9.3745 - val_loss: 67.4477 - val_mae: 6.2839\nEpoch 3/5\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 5s/step - loss: 77.5290 - mae: 6.7403 - val_loss: 37.6809 - val_mae: 4.5498\nEpoch 4/5\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 5s/step - loss: 51.8672 - mae: 5.4728 - val_loss: 28.2894 - val_mae: 3.8733\nEpoch 5/5\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 5s/step - loss: 43.1938 - mae: 4.9533 - val_loss: 23.2202 - val_mae: 3.4903\n",
          "output_type": "stream"
        },
        {
          "execution_count": 22,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<keras.src.callbacks.history.History at 0x7ed1da7b73d0>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2=trainfun(efficientnet_model)\n",
        "model2.fit(X_train_rgb,y_train,epochs =5,batch_size = 256,validation_split = 0.2)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-01T23:41:11.130694Z",
          "iopub.execute_input": "2024-04-01T23:41:11.131042Z",
          "iopub.status.idle": "2024-04-01T23:53:25.774879Z",
          "shell.execute_reply.started": "2024-04-01T23:41:11.131014Z",
          "shell.execute_reply": "2024-04-01T23:53:25.773653Z"
        },
        "trusted": true,
        "id": "2vS6hn3_bUt9",
        "outputId": "d98f1d33-e1b3-412f-a43f-d0e192b0cf32"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/5\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 7s/step - loss: 2150.8955 - mae: 42.2947 - val_loss: 395.5820 - val_mae: 15.5772\nEpoch 2/5\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 6s/step - loss: 280.0997 - mae: 13.1886 - val_loss: 113.1493 - val_mae: 8.2016\nEpoch 3/5\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 7s/step - loss: 98.6514 - mae: 7.5761 - val_loss: 50.6105 - val_mae: 5.0952\nEpoch 4/5\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 6s/step - loss: 55.5512 - mae: 5.3673 - val_loss: 38.5260 - val_mae: 4.2299\nEpoch 5/5\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 7s/step - loss: 43.2571 - mae: 4.6454 - val_loss: 32.3522 - val_mae: 3.9405\n",
          "output_type": "stream"
        },
        {
          "execution_count": 23,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<keras.src.callbacks.history.History at 0x7ed1d8510be0>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3=trainfun(vgg19_model)\n",
        "model3.fit(X_train_rgb,y_train,epochs =5,batch_size = 256,validation_split = 0.2)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-01T23:53:25.776539Z",
          "iopub.execute_input": "2024-04-01T23:53:25.777055Z",
          "iopub.status.idle": "2024-04-02T00:24:35.516887Z",
          "shell.execute_reply.started": "2024-04-01T23:53:25.777025Z",
          "shell.execute_reply": "2024-04-02T00:24:35.515658Z"
        },
        "trusted": true,
        "id": "QEbkEX5vbUt9",
        "outputId": "f1e392c0-e1cc-48bc-a8c3-066c8fe80bcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/5\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m361s\u001b[0m 20s/step - loss: 1466.9417 - mae: 32.2074 - val_loss: 273.3984 - val_mae: 11.9073\nEpoch 2/5\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m384s\u001b[0m 20s/step - loss: 229.0069 - mae: 11.6447 - val_loss: 138.8029 - val_mae: 9.0945\nEpoch 3/5\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m360s\u001b[0m 20s/step - loss: 150.7518 - mae: 9.4315 - val_loss: 108.7550 - val_mae: 8.0666\nEpoch 4/5\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 20s/step - loss: 123.6641 - mae: 8.5643 - val_loss: 91.6880 - val_mae: 7.3585\nEpoch 5/5\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 20s/step - loss: 105.6342 - mae: 7.8627 - val_loss: 80.7559 - val_mae: 6.8853\n",
          "output_type": "stream"
        },
        {
          "execution_count": 24,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<keras.src.callbacks.history.History at 0x7ed1c8bb2500>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model4=trainfun(densenet_model)\n",
        "model4.fit(X_train_rgb,y_train,epochs =5,batch_size = 256,validation_split = 0.2)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-02T00:24:35.520425Z",
          "iopub.execute_input": "2024-04-02T00:24:35.521176Z",
          "iopub.status.idle": "2024-04-02T00:36:00.693062Z",
          "shell.execute_reply.started": "2024-04-02T00:24:35.521143Z",
          "shell.execute_reply": "2024-04-02T00:36:00.69129Z"
        },
        "trusted": true,
        "id": "HY_R8QpWbUt9",
        "outputId": "589b98be-be71-453e-d06d-d80cd8c52e17"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/5\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 6s/step - loss: 1120.9617 - mae: 26.4212 - val_loss: 231.8927 - val_mae: 12.2796\nEpoch 2/5\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 5s/step - loss: 228.8987 - mae: 11.9610 - val_loss: 124.3937 - val_mae: 8.5608\nEpoch 3/5\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 5s/step - loss: 141.6135 - mae: 9.2825 - val_loss: 80.5321 - val_mae: 6.7022\nEpoch 4/5\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 5s/step - loss: 98.9215 - mae: 7.6882 - val_loss: 56.5455 - val_mae: 5.6161\nEpoch 5/5\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 5s/step - loss: 73.7886 - mae: 6.6371 - val_loss: 45.3091 - val_mae: 5.0742\n",
          "output_type": "stream"
        },
        {
          "execution_count": 25,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<keras.src.callbacks.history.History at 0x7ed1cb5592d0>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model5=trainfun(mobilenet_model)\n",
        "model5.fit(X_train_rgb,y_train,epochs =5,batch_size = 256,validation_split = 0.2)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-02T00:36:00.712384Z",
          "iopub.execute_input": "2024-04-02T00:36:00.712868Z",
          "iopub.status.idle": "2024-04-02T00:38:58.12554Z",
          "shell.execute_reply.started": "2024-04-02T00:36:00.712829Z",
          "shell.execute_reply": "2024-04-02T00:38:58.124227Z"
        },
        "trusted": true,
        "id": "ydt8V2X0bUt9",
        "outputId": "d5480e3a-24de-4288-b57c-912a2e8ce0fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/5\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1s/step - loss: 1892.3571 - mae: 38.6905 - val_loss: 209.7957 - val_mae: 11.5428\nEpoch 2/5\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1s/step - loss: 224.1553 - mae: 11.2316 - val_loss: 83.1424 - val_mae: 7.6923\nEpoch 3/5\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - loss: 70.9693 - mae: 6.6856 - val_loss: 30.1498 - val_mae: 4.1475\nEpoch 4/5\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - loss: 37.3103 - mae: 4.6533 - val_loss: 23.2466 - val_mae: 3.5529\nEpoch 5/5\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - loss: 31.7413 - mae: 4.3009 - val_loss: 19.3552 - val_mae: 3.1858\n",
          "output_type": "stream"
        },
        {
          "execution_count": 26,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<keras.src.callbacks.history.History at 0x7ed1b1913f40>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#preparing test data\n",
        "timag = []\n",
        "for i in range(0,1783):\n",
        "    timg = test_data['Image'][i].split(' ')\n",
        "    timg = ['0' if x == '' else x for x in timg]\n",
        "\n",
        "    timag.append(timg)"
      ],
      "metadata": {
        "id": "KTFFr14cbaiL",
        "execution": {
          "iopub.status.busy": "2024-04-02T00:43:00.111986Z",
          "iopub.execute_input": "2024-04-02T00:43:00.112438Z",
          "iopub.status.idle": "2024-04-02T00:43:03.893769Z",
          "shell.execute_reply.started": "2024-04-02T00:43:00.112406Z",
          "shell.execute_reply": "2024-04-02T00:43:03.892356Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "timage_list = np.array(timag,dtype = 'float')\n",
        "X_test = timage_list.reshape(-1,96,96,1)"
      ],
      "metadata": {
        "id": "IivHrqGNcEoT",
        "execution": {
          "iopub.status.busy": "2024-04-02T00:44:22.370556Z",
          "iopub.execute_input": "2024-04-02T00:44:22.370995Z",
          "iopub.status.idle": "2024-04-02T00:44:25.70354Z",
          "shell.execute_reply.started": "2024-04-02T00:44:22.370959Z",
          "shell.execute_reply": "2024-04-02T00:44:25.70244Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "id": "40DR1okOp0C0",
        "execution": {
          "iopub.status.busy": "2024-04-02T00:43:43.550904Z",
          "iopub.execute_input": "2024-04-02T00:43:43.551835Z",
          "iopub.status.idle": "2024-04-02T00:43:43.560538Z",
          "shell.execute_reply.started": "2024-04-02T00:43:43.551797Z",
          "shell.execute_reply": "2024-04-02T00:43:43.559338Z"
        },
        "trusted": true,
        "outputId": "7510d08e-bb80-4690-eded-7ac18194e0ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 44,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(1783, 96, 96, 1)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf_tensor = tf.convert_to_tensor(X_test, dtype=tf.float32)\n",
        "# Assuming X_train is your grayscale image dataset with shape (num_images, 96, 96, 1)\n",
        "X_test = tf.image.grayscale_to_rgb(tf_tensor)"
      ],
      "metadata": {
        "id": "MSXunKEmpfDd",
        "execution": {
          "iopub.status.busy": "2024-04-02T00:44:31.163281Z",
          "iopub.execute_input": "2024-04-02T00:44:31.163731Z",
          "iopub.status.idle": "2024-04-02T00:44:31.452922Z",
          "shell.execute_reply.started": "2024-04-02T00:44:31.163698Z",
          "shell.execute_reply": "2024-04-02T00:44:31.45173Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred1 = model.predict(X_test)\n",
        "pred2 = model2.predict(X_test)\n",
        "pred3 = model3.predict(X_test)\n",
        "pred4 = model4.predict(X_test)\n",
        "pred5 = model5.predict(X_test)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-02T00:44:35.931442Z",
          "iopub.execute_input": "2024-04-02T00:44:35.932273Z",
          "iopub.status.idle": "2024-04-02T00:49:00.06748Z",
          "shell.execute_reply.started": "2024-04-02T00:44:35.932217Z",
          "shell.execute_reply": "2024-04-02T00:49:00.066396Z"
        },
        "trusted": true,
        "id": "0IW9t1U1bUuE",
        "outputId": "966b00cb-5cdd-45f1-d983-a491420a0eca"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 500ms/step\n\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 564ms/step\n\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 2s/step\n\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 530ms/step\n\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 132ms/step\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred=(pred5+pred4)/2"
      ],
      "metadata": {
        "id": "L8ru8xUha9MD",
        "execution": {
          "iopub.status.busy": "2024-04-02T00:57:44.42444Z",
          "iopub.execute_input": "2024-04-02T00:57:44.425187Z",
          "iopub.status.idle": "2024-04-02T00:57:44.430519Z",
          "shell.execute_reply.started": "2024-04-02T00:57:44.42515Z",
          "shell.execute_reply": "2024-04-02T00:57:44.429359Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lookid_data = pd.read_csv('/kaggle/input/facial-keypoints-detection/IdLookupTable.csv')\n",
        "lookid_list = list(lookid_data['FeatureName'])\n",
        "imageID = list(lookid_data['ImageId']-1)\n",
        "pre_list = list(pred)\n",
        "rowid = lookid_data['RowId']\n",
        "rowid=list(rowid)\n",
        "feature = []\n",
        "for f in list(lookid_data['FeatureName']):\n",
        "    feature.append(lookid_list.index(f))\n",
        "preded = []\n",
        "for x,y in zip(imageID,feature):\n",
        "    preded.append(pre_list[x][y])\n",
        "rowid = pd.Series(rowid,name = 'RowId')\n",
        "loc = pd.Series(preded,name = 'Location')\n",
        "submission = pd.concat([rowid,loc],axis = 1)\n",
        "submission.to_csv('/kaggle/working/face_key_detection_submission.csv',index = False)"
      ],
      "metadata": {
        "id": "0RibNmMn6ZxW",
        "execution": {
          "iopub.status.busy": "2024-04-02T00:57:47.138661Z",
          "iopub.execute_input": "2024-04-02T00:57:47.139365Z",
          "iopub.status.idle": "2024-04-02T00:57:47.31225Z",
          "shell.execute_reply.started": "2024-04-02T00:57:47.139315Z",
          "shell.execute_reply": "2024-04-02T00:57:47.310934Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fd=pd.read_csv('/kaggle/working/face_key_detection_submission.csv')"
      ],
      "metadata": {
        "id": "Zc_a61AbsEv-",
        "execution": {
          "iopub.status.busy": "2024-04-02T00:57:50.047017Z",
          "iopub.execute_input": "2024-04-02T00:57:50.047777Z",
          "iopub.status.idle": "2024-04-02T00:57:50.064461Z",
          "shell.execute_reply.started": "2024-04-02T00:57:50.047729Z",
          "shell.execute_reply": "2024-04-02T00:57:50.063195Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TeA6wu_js-Vk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fd[fd['Location'] > 96]"
      ],
      "metadata": {
        "id": "fm1HIi4F7POd",
        "execution": {
          "iopub.status.busy": "2024-04-02T00:57:51.543654Z",
          "iopub.execute_input": "2024-04-02T00:57:51.544083Z",
          "iopub.status.idle": "2024-04-02T00:57:51.555664Z",
          "shell.execute_reply.started": "2024-04-02T00:57:51.544045Z",
          "shell.execute_reply": "2024-04-02T00:57:51.554628Z"
        },
        "trusted": true,
        "outputId": "36e5766e-9483-492d-c9cc-dcb5571f52f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 85,
          "output_type": "execute_result",
          "data": {
            "text/plain": "       RowId    Location\n9462    9463   96.039640\n9477    9478   97.489160\n15121  15122   96.277070\n22483  22484  103.636505\n23795  23796   99.541565",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RowId</th>\n      <th>Location</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9462</th>\n      <td>9463</td>\n      <td>96.039640</td>\n    </tr>\n    <tr>\n      <th>9477</th>\n      <td>9478</td>\n      <td>97.489160</td>\n    </tr>\n    <tr>\n      <th>15121</th>\n      <td>15122</td>\n      <td>96.277070</td>\n    </tr>\n    <tr>\n      <th>22483</th>\n      <td>22484</td>\n      <td>103.636505</td>\n    </tr>\n    <tr>\n      <th>23795</th>\n      <td>23796</td>\n      <td>99.541565</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fd.loc[fd['Location'] > 96, 'Location'] = 95\n",
        "submission = fd"
      ],
      "metadata": {
        "id": "wJO5gNR2sN6l",
        "execution": {
          "iopub.status.busy": "2024-04-02T00:57:54.978457Z",
          "iopub.execute_input": "2024-04-02T00:57:54.978901Z",
          "iopub.status.idle": "2024-04-02T00:57:54.985764Z",
          "shell.execute_reply.started": "2024-04-02T00:57:54.978867Z",
          "shell.execute_reply": "2024-04-02T00:57:54.984512Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission.to_csv('/kaggle/working/face_key_detection_submission.csv',index = False)"
      ],
      "metadata": {
        "id": "n74cnqEhtVyN",
        "execution": {
          "iopub.status.busy": "2024-04-02T00:57:57.736525Z",
          "iopub.execute_input": "2024-04-02T00:57:57.737249Z",
          "iopub.status.idle": "2024-04-02T00:57:57.811925Z",
          "shell.execute_reply.started": "2024-04-02T00:57:57.737211Z",
          "shell.execute_reply": "2024-04-02T00:57:57.810696Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}